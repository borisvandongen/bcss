Summary:

**Topic Covered:**
Data-Driven Algorithms using Offline Data

**Virtual Coach Example:**
- A decision-making process of a virtual coach (or a conversational agent) is explained with an example involving individuals Laura, Mary, David, and John in the context of smoking cessation.
- Decisions are based on message ratings by these individuals, and the goal is to send motivational messages to help quit smoking.

**Concepts Introduced:**
- **Offline Data Usage:** Algorithms that rely solely on previously gathered data.
- **Weighted Average Ratings:** The importance of ratings is adjusted based on the similarity of the raters to the recipient (e.g., similarity in terms of nicotine dependence).
- **Nicotine Dependence:** A trait used to determine similarity between individuals which affects the weighting of their message ratings.

**Experimental Method:**
- Study compared two algorithms:
  - **Hybrid Algorithm:** Utilized weighted average ratings based on similarity (akin to collaborative filtering).
  - **Knowledge-Based Algorithm (KBA):** Did not use similarity ratings for decision-making.
- Participants rated messages from 1 to 5 stars.
- Results showed no significant difference in message appreciation between the two conditions.

**Implications for Algorithms:**
- **Data Requirements:** Need for offline data and potentially other user-related data (traits or states).
- **Effectiveness:** It may not inherently improve with the usage of offline data unless online data is also incorporated.
- **Explainability and Predictability:**
  - Varies with algorithm complexity.
  - More complex algorithms or the addition of online data make the system less predictable and potentially less explainable without additional techniques.

The video concludes by underscoring that the use of offline data in algorithms comes with various challenges related to effectiveness, explainability, and predictability, and these attributes are influenced by the complexity of the algorithm and the incorporation of online data. Further exploration of online data use is postponed to subsequent videos.

## Transcript

Welcome to our next video. This one is about data-driven algorithms, and we will look at offline data first. So in this case, a virtual coach, conversation agent, etc. makes a decision based on data that has been gathered. Looking at the big overview slide, we are now in the third column, and we're looking at another component of the algorithm by Horsfrile to illustrate this. So again, we have Laura here, and from the previous example, we had two messages left that we could send to Laura. The green message and the yellow message. And what we also now have is that we have some other people in our intervention, Mary, David, and John. And these people have seen these messages before, and they've rated them. And we overall have an average rating of three stars for the green message and four stars for the yellow message. So based on this, we would send the yellow message to Laura. But in fact, we have more information than just that. More precisely, we also know people's nicotine dependence here in the context of quitting smoking. So Laura's nicotine dependence is with 9 out of 10 quite high. And we also know the nicotine dependence of the people in our data set. So Mary and David have a rather low nicotine dependence, and John also has a high one. And when we now look at these individual ratings that these three people have given for the two messages, we see that Mary has given just two stars for the green message and five stars for the yellow message. And similar responses have been given by David. And John, who's actually the most similar to Laura, actually gave a five-star rating for the green message and just two stars for the yellow one. So based on this, we would now send the green message. The idea is that we give a higher weight to the ratings given by more similar people. Here we now just have the nicotine dependence. In the paper, they also look at other characteristics of people, many more actually. But the idea is still the same. We gather these ratings, and then we compute some sort of weighted average where the similarity between people is taken into account. The authors of this algorithm have tested this algorithm in the context of smoking cessation. So there was an initial questionnaire where people filled in all these variables that were needed for the similarity rating, for example, the age. Then people received, during the behavior change process, motivational messages of decreasing frequency. So for example, five on the quit date, then one per day in the remaining days of the first week, and then even fewer messages later on. And people rated messages with one to five stars. And there were two conditions. One was with this kind of similarity rating. It's called the hybrid algorithm. And the other one was without this kind of similarity rating, which is also called collaborative filtering in the recommender system literature. And that baseline algorithm without the collaborative filtering was called the knowledge-based algorithm, or KBA, here in the slides. And if we now here look at the message appreciation expressed by the people in the two conditions during the behavior change process, we see that there is really no significant difference between the two conditions at any point. So this, again, shows this difficulty of using tailored messages to affect people's behavior, and in this case, even just the message appreciation. So what have we seen? Well, we had some sort of artificial agent that makes its decisions based on data that has been collected. And now the question is, what do we need for such an algorithm? Well, obviously, we need offline data. And then there might also be, again, other things that we need, such as data on the user state or data on user traits. So here, for example, we needed information on people's nicotine dependence. And as I mentioned, the paper also shows other characteristics of people. What do we get from such an algorithm? Well, again, about the effectiveness, that kind of depends. So if you really just only use offline data, of course, the effectiveness, again, won't change during the lifetime of the algorithm as being used in the intervention. But as we'll see, many algorithms actually also use online data. So they add data during the application. And so does also the algorithm by Horsfreid, actually. And the explainability, well, that depends on the algorithm that you're using and how complex it is. Oftentimes, there are, of course, techniques that you can use to explain algorithm decisions. But how explainable the decision-making is, just as it is, really depends on the algorithm that you choose. And yes, you might have to add something on top to explain the decisions. And with the predictability, again, that really depends on the algorithm that you're choosing. If you just have a decision tree with maybe two levels, then it might be very easy. And with more complex algorithms, it becomes increasingly difficult. And of course, also, if you add online data, that becomes even harder, as we'll see in one of the other videos on using online data. So this concludes our video on data-driven algorithms that use offline data. See you in the next video.